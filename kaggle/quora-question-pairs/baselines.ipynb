{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random as rnd\n",
    "from collections import defaultdict\n",
    "\n",
    "import nltk\n",
    "import trax\n",
    "from trax import layers as tl\n",
    "from trax.supervised import training\n",
    "from trax.fastmath import numpy as fastnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing: from questions to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid1  qid2                                          question1  \\\n",
       "id                                                                  \n",
       "0      1     2  What is the step by step guide to invest in sh...   \n",
       "1      3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2      5     6  How can I increase the speed of my internet co...   \n",
       "3      7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4      9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                            question2  is_duplicate  \n",
       "id                                                                   \n",
       "0   What is the step by step guide to invest in sh...             0  \n",
       "1   What would happen if the Indian government sto...             0  \n",
       "2   How can Internet speed be increased by hacking...             0  \n",
       "3   Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4             Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv.zip', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363861, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.1)\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40429, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_index = data_train.index[data_train.is_duplicate == 1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the vocabulary is:  39279\n"
     ]
    }
   ],
   "source": [
    "Q1_train_words = data_train.loc[td_index].question1.values\n",
    "Q2_train_words = data_train.loc[td_index].question2.values\n",
    "\n",
    "Q1_test_words = data_test.question1.values\n",
    "Q2_test_words = data_test.question2.values\n",
    "y_test  = data_test.is_duplicate.values\n",
    "\n",
    "#create arrays\n",
    "Q1_train = np.empty_like(Q1_train_words)\n",
    "Q2_train = np.empty_like(Q2_train_words)\n",
    "\n",
    "Q1_test = np.empty_like(Q1_test_words)\n",
    "Q2_test = np.empty_like(Q2_test_words)\n",
    "\n",
    "# Building the vocabulary with the train set         (this might take a minute)\n",
    "vocab = defaultdict(lambda: 0)\n",
    "vocab['<PAD>'] = 1\n",
    "\n",
    "for idx in range(len(Q1_train_words)):\n",
    "    Q1_train[idx] = nltk.word_tokenize(Q1_train_words[idx])\n",
    "    Q2_train[idx] = nltk.word_tokenize(Q2_train_words[idx])\n",
    "    q = Q1_train[idx] + Q2_train[idx]\n",
    "    for word in q:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab) + 1\n",
    "print('The length of the vocabulary is: ', len(vocab))\n",
    "\n",
    "for idx in range(len(Q1_test_words)): \n",
    "    Q1_test[idx] = nltk.word_tokenize(Q1_test_words[idx])\n",
    "    Q2_test[idx] = nltk.word_tokenize(Q2_test_words[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting questions to array of integers\n",
    "for i in range(len(Q1_train)):\n",
    "    Q1_train[i] = [vocab[word] for word in Q1_train[i]]\n",
    "    Q2_train[i] = [vocab[word] for word in Q2_train[i]]\n",
    "\n",
    "        \n",
    "for i in range(len(Q1_test)):\n",
    "    Q1_test[i] = [vocab[word] for word in Q1_test[i]]\n",
    "    Q2_test[i] = [vocab[word] for word in Q2_test[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Siamese(vocab_size=len(vocab), d_model=128, mode='train'):\n",
    "    \"\"\"Returns a Siamese model.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int, optional): Length of the vocabulary. Defaults to len(vocab).\n",
    "        d_model (int, optional): Depth of the model. Defaults to 128.\n",
    "        mode (str, optional): 'train', 'eval' or 'predict', predict mode is for fast inference. Defaults to 'train'.\n",
    "\n",
    "    Returns:\n",
    "        trax.layers.combinators.Parallel: A Siamese model. \n",
    "    \"\"\"\n",
    "\n",
    "    def normalize(x):  # normalizes the vectors to have L2 norm 1\n",
    "        return x / fastnp.sqrt(fastnp.sum(x * x, axis=-1, keepdims=True))\n",
    "    \n",
    "    q_processor = tl.Serial(  # Processor will run on Q1 and Q2.\n",
    "        tl.Embedding(vocab_size, d_model), # Embedding layer\n",
    "        tl.LSTM(d_model), # LSTM layer\n",
    "        tl.Mean(axis=1), # Mean over columns\n",
    "        tl.Fn('Normalize', lambda x: normalize(x))  # Apply normalize function\n",
    "    )  # Returns one vector of shape [batch_size, d_model].\n",
    "        \n",
    "    # Run on Q1 and Q2 in parallel.\n",
    "    model = tl.Parallel(q_processor, q_processor)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louis.guitton/workspace/papers/venv/lib/python3.8/site-packages/jax/lib/xla_bridge.py:130: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "# Loading in the saved model\n",
    "model = Siamese()\n",
    "model.init_from_file('coursera_pretrained_siamese.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('test.csv', index_col=0).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2345796/2345796 [08:50<00:00, 4425.78it/s]\n",
      "100%|██████████| 2345796/2345796 [00:10<00:00, 223308.29it/s]\n"
     ]
    }
   ],
   "source": [
    "Q1_test_words = data_test.question1.values\n",
    "Q2_test_words = data_test.question2.values\n",
    "\n",
    "Q1_test = np.empty_like(Q1_test_words)\n",
    "Q2_test = np.empty_like(Q2_test_words)\n",
    "\n",
    "for idx in tqdm(range(len(Q1_test_words))): \n",
    "    Q1_test[idx] = nltk.word_tokenize(Q1_test_words[idx])\n",
    "    Q2_test[idx] = nltk.word_tokenize(Q2_test_words[idx])\n",
    "\n",
    "for i in tqdm(range(len(Q1_test))):\n",
    "    Q1_test[i] = [vocab[word] for word in Q1_test[i]]\n",
    "    Q2_test[i] = [vocab[word] for word in Q2_test[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('question1_tensors.pickle', 'wb') as fh:\n",
    "    pickle.dump(Q1_test, fh)\n",
    "\n",
    "with open('question2_tensors.pickle', 'wb') as fh:\n",
    "    pickle.dump(Q2_test, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('question1_tensors.pickle', 'rb') as fh:\n",
    "    b = pickle.load(fh)\n",
    "\n",
    "assert (Q1_test == b).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(Q1, Q2, batch_size, pad=1, shuffle=True):\n",
    "    \"\"\"Generator function that yields batches of data\n",
    "\n",
    "    Args:\n",
    "        Q1 (list): List of transformed (to tensor) questions.\n",
    "        Q2 (list): List of transformed (to tensor) questions.\n",
    "        batch_size (int): Number of elements per batch.\n",
    "        pad (int, optional): Pad character from the vocab. Defaults to 1.\n",
    "        shuffle (bool, optional): If the batches should be randomnized or not. Defaults to True.\n",
    "    Yields:\n",
    "        tuple: Of the form (input1, input2) with types (numpy.ndarray, numpy.ndarray)\n",
    "        NOTE: input1: inputs to your model [q1a, q2a, q3a, ...] i.e. (q1a,q1b) are duplicates\n",
    "              input2: targets to your model [q1b, q2b,q3b, ...] i.e. (q1a,q2i) i!=a are not duplicates\n",
    "    \"\"\"\n",
    "\n",
    "    input1 = []\n",
    "    input2 = []\n",
    "    idx = 0\n",
    "    len_q = len(Q1)\n",
    "    question_indexes = [*range(len_q)]\n",
    "    \n",
    "    if shuffle:\n",
    "        rnd.shuffle(question_indexes)\n",
    "    \n",
    "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "    while True:\n",
    "        if idx >= len_q:\n",
    "            # if idx is greater than or equal to len_q, set idx accordingly \n",
    "            # (Hint: look at the instructions above)\n",
    "            idx = 0\n",
    "            # shuffle to get random batches if shuffle is set to True\n",
    "            if shuffle:\n",
    "                rnd.shuffle(question_indexes)\n",
    "        \n",
    "        # get questions at the `question_indexes[idx]` position in Q1 and Q2\n",
    "        q1 = Q1[question_indexes[idx]]\n",
    "        q2 = Q2[question_indexes[idx]]\n",
    "        \n",
    "        # increment idx by 1\n",
    "        idx += 1\n",
    "        # append q1\n",
    "        input1.append(q1)\n",
    "        # append q2\n",
    "        input2.append(q2)\n",
    "        if len(input1) == batch_size:\n",
    "            # determine max_len as the longest question in input1 & input 2\n",
    "            # Hint: use the `max` function. \n",
    "            # take max of input1 & input2 and then max out of the two of them.\n",
    "            max_len = max(max([len(l) for l in input1]), max([len(l) for l in input2]))\n",
    "            # ceil to power-of-2 (Hint: look at the instructions above)\n",
    "            max_len = 2**int(np.ceil(np.log2(max_len)))\n",
    "            b1 = []\n",
    "            b2 = []\n",
    "            for q1, q2 in zip(input1, input2):\n",
    "                # add [pad] to q1 until it reaches max_len\n",
    "                q1 += [pad] * (max_len - len(q1))\n",
    "                # add [pad] to q2 until it reaches max_len\n",
    "                q2 += [pad] * (max_len - len(q2))\n",
    "                # append q1\n",
    "                b1.append(q1)\n",
    "                # append q2\n",
    "                b2.append(q2)\n",
    "            # use b1 and b2\n",
    "            yield np.array(b1), np.array(b2)\n",
    "            # reset the batches\n",
    "            input1, input2 = [], []  # reset the batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batches: 100%|██████████| 9164/9164 [2:44:54<00:00,  1.08s/it]   \n"
     ]
    }
   ],
   "source": [
    "batch_size=256\n",
    "predictions = {}\n",
    "\n",
    "for i in tqdm(range(0, len(Q1_test), batch_size), desc=\"batches\"):\n",
    "    # Call the data generator (built in Ex 01) with shuffle=False using next()\n",
    "    # use batch size chuncks of questions as Q1 & Q2 arguments of the data generator. e.g x[i:i + batch_size]\n",
    "    # Hint: use `vocab['<PAD>']` for the `pad` argument of the data generator\n",
    "    q1, q2 = next(data_generator(\n",
    "        Q1_test[i:i + batch_size], \n",
    "        Q2_test[i:i + batch_size], \n",
    "        batch_size, \n",
    "        pad=vocab['<PAD>'], \n",
    "        shuffle=False\n",
    "    ))\n",
    "\n",
    "    # Call the model\n",
    "    v1, v2 = model((q1, q2))\n",
    "\n",
    "    for j in range(batch_size):\n",
    "        # take dot product to compute cos similarity of each pair of entries, v1[j], v2[j]\n",
    "        # don't forget to transpose the second argument\n",
    "        d = fastnp.dot(v1[j], v2[j].T)\n",
    "\n",
    "        predictions[i + j] = float(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"similarity\"] = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>788812</th>\n",
       "      <td>Who invented the harp? What purpose does it se...</td>\n",
       "      <td>Who invented the marimba? What purpose does it...</td>\n",
       "      <td>1.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623887</th>\n",
       "      <td>How much money is spent during the 4 years in ...</td>\n",
       "      <td>How much money is spent during the 4 years in ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668926</th>\n",
       "      <td>What is the corporate culture like at ARRIS Gr...</td>\n",
       "      <td>What is the corporate culture like at Radian G...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86449</th>\n",
       "      <td>Is NH4NO3 soluble in water? Why or why not?</td>\n",
       "      <td>Is Hg2Cl2 soluble in water? Why or why not?</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449998</th>\n",
       "      <td>How do I register on www.edisha.gov.in?</td>\n",
       "      <td>How do I register on Rackons.com?</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661148</th>\n",
       "      <td>Can the degree of a differential equation be a...</td>\n",
       "      <td>How is calculus used in the real world?</td>\n",
       "      <td>-0.418509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604158</th>\n",
       "      <td>What does media marketing vs search engine mar...</td>\n",
       "      <td>How can you look at someone's private Instagra...</td>\n",
       "      <td>-0.421759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160733</th>\n",
       "      <td>Prisoner pardon blue red hat Google?</td>\n",
       "      <td>What can Adolf Hitler fight alongside Bavarian...</td>\n",
       "      <td>-0.434188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848683</th>\n",
       "      <td>Is here the sky purple?</td>\n",
       "      <td>How I get direct client for BPO campaigns on u...</td>\n",
       "      <td>-0.449001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151009</th>\n",
       "      <td>Websites for preparing</td>\n",
       "      <td>Why do we remember quora?</td>\n",
       "      <td>-0.473442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2345796 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question1  \\\n",
       "test_id                                                      \n",
       "788812   Who invented the harp? What purpose does it se...   \n",
       "623887   How much money is spent during the 4 years in ...   \n",
       "1668926  What is the corporate culture like at ARRIS Gr...   \n",
       "86449          Is NH4NO3 soluble in water? Why or why not?   \n",
       "449998             How do I register on www.edisha.gov.in?   \n",
       "...                                                    ...   \n",
       "1661148  Can the degree of a differential equation be a...   \n",
       "604158   What does media marketing vs search engine mar...   \n",
       "1160733               Prisoner pardon blue red hat Google?   \n",
       "1848683                            Is here the sky purple?   \n",
       "2151009                            Websites for preparing    \n",
       "\n",
       "                                                 question2  similarity  \n",
       "test_id                                                                 \n",
       "788812   Who invented the marimba? What purpose does it...    1.000001  \n",
       "623887   How much money is spent during the 4 years in ...    1.000000  \n",
       "1668926  What is the corporate culture like at Radian G...    1.000000  \n",
       "86449          Is Hg2Cl2 soluble in water? Why or why not?    1.000000  \n",
       "449998                   How do I register on Rackons.com?    1.000000  \n",
       "...                                                    ...         ...  \n",
       "1661148            How is calculus used in the real world?   -0.418509  \n",
       "604158   How can you look at someone's private Instagra...   -0.421759  \n",
       "1160733  What can Adolf Hitler fight alongside Bavarian...   -0.434188  \n",
       "1848683  How I get direct client for BPO campaigns on u...   -0.449001  \n",
       "2151009                          Why do we remember quora?   -0.473442  \n",
       "\n",
       "[2345796 rows x 3 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.sort_values(by=\"similarity\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE = data_train.is_duplicate.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_id\n",
       "0          0.177522\n",
       "1          0.282551\n",
       "2          0.417358\n",
       "3         -0.040349\n",
       "4          0.108711\n",
       "             ...   \n",
       "2345791    0.183330\n",
       "2345792    0.156098\n",
       "2345793    0.133667\n",
       "2345794    0.777241\n",
       "2345795    0.033396\n",
       "Name: similarity, Length: 2345796, dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds = data_test.similarity / (1 - data_test.similarity)\n",
    "scaled_odds = SCALE * odds\n",
    "scaled_odds / (1 + scaled_odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_test.sample(10000).similarity.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"is_duplicate\"] = data_test.similarity.clip(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>similarity</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "      <td>0.368825</td>\n",
       "      <td>0.368825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "      <td>0.516025</td>\n",
       "      <td>0.516025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "      <td>0.659785</td>\n",
       "      <td>0.659785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "      <td>-0.117321</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "      <td>0.248243</td>\n",
       "      <td>0.248243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question1  \\\n",
       "test_id                                                      \n",
       "0        How does the Surface Pro himself 4 compare wit...   \n",
       "1        Should I have a hair transplant at age 24? How...   \n",
       "2        What but is the best way to send money from Ch...   \n",
       "3                              Which food not emulsifiers?   \n",
       "4                         How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                                 question2  similarity  \\\n",
       "test_id                                                                  \n",
       "0        Why did Microsoft choose core m3 and not core ...    0.368825   \n",
       "1              How much cost does hair transplant require?    0.516025   \n",
       "2                            What you send money to China?    0.659785   \n",
       "3                                        What foods fibre?   -0.117321   \n",
       "4                           How their can I start reading?    0.248243   \n",
       "\n",
       "         is_duplicate  \n",
       "test_id                \n",
       "0            0.368825  \n",
       "1            0.516025  \n",
       "2            0.659785  \n",
       "3            0.000000  \n",
       "4            0.248243  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.is_duplicate.to_csv(\"siamese_lstm_network.csv.gz\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 24.6M/24.6M [04:05<00:00, 105kB/s]\n",
      "Successfully submitted to Quora Question Pairs"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit \\\n",
    "    -f siamese_lstm_network.csv.gz \\\n",
    "    -m 'Siamese LSTM networks trained with triplet loss' \\\n",
    "    quora-question-pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
